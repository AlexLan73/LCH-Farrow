# 📋 ОБЩИЙ ПЛАН РАБОТ - LCH-Farrow OpenCL Benchmark

## 🎯 ЦЕЛЬ ПРОЕКТА

Разработать Multi-GPU Benchmark на OpenCL для Ubuntu (RTX3060) с поддержкой NVIDIA и AMD GPU. Реализовать дробную задержку сигнала с интерполяцией Лагранжа до формирования матрицы с задержанными сигналами. Поддержка опционального вывода результата с GPU для анализа.

---

## 🏗️ АРХИТЕКТУРА ПРОЕКТА

### Трёхслойная архитектура

```
┌─────────────────────────────────────────┐
│  СЛОЙ 1: C++ Приложение (платформа-независимо) │
│  - SignalBuffer: загрузка/сохранение данных     │
│  - FilterBank: FIR коэффициенты + опорный ЛЧМ  │
│  - ProcessingPipeline: координация обработки   │
│  - ProfilingEngine: измерение времени           │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│  СЛОЙ 2: GPU Абстракция (виртуальный интерфейс)│
│  - IGPUBackend: abstract class                 │
│  - OpenCLBackend: реализация для OpenCL         │
│  - GPUFactory: выбор оптимального GPU           │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│  СЛОЙ 3: OpenCL Код (специфичный для платформы)│
│  - kernel_fractional_delay.cl: дробная задержка│
│  - (FFT/IFFT/Hadamard - убраны из текущей версии) │
└─────────────────────────────────────────┘
```

---

## 📦 ОСНОВНЫЕ КОМПОНЕНТЫ

### 1. SignalBuffer (Управление данными)
- **Назначение**: Загрузка, хранение и сохранение сигналов
- **Данные**: 1-256 лучей, 100-1300000 комплексных точек на луч
- **Тип**: `vector<complex<float>>` (совместимо с OpenCL)
- **Функции**: LoadFromFile(), SaveToFile(), GetBeam(), GetNumBeams()

### 2. FilterBank (Фильтрация и опорный сигнал)
- **Назначение**: Хранение FIR коэффициентов и опорного ЛЧМ сигнала
- **Опорный сигнал**: ЛЧМ (линейно-частотная модуляция)
- **Функции**: LoadCoefficients(), PrecomputeReferenceFft(), GetReferenceFft()

### 3. ProcessingPipeline (Оркестрация обработки)
- **Назначение**: Координация этапов обработки до формирования матрицы с задержанными сигналами
- **Этапы**: 
  1. H2D Transfer (загрузка данных на GPU)
  2. Дробная задержка сигнала (формирование матрицы с задержанными сигналами)
  3. Опционально: D2H Transfer (вывод с GPU для анализа)
- **Функции**: ExecuteFull(copy_to_host), ProfileKernel(), ValidateResults()
- **Режимы работы**:
  - `copy_to_host = false`: результат остаётся на GPU для дальнейшей обработки
  - `copy_to_host = true`: результат копируется на хост для анализа

### 4. OpenCLBackend (GPU обработка)
- **Назначение**: Реализация обработки на GPU через OpenCL
- **Поддержка**: NVIDIA (RTX3060) и AMD GPU
- **Функции**: ExecuteConvolution(), AllocateMemory(), FreeMemory()

### 5. ProfilingEngine (Профилирование)
- **Назначение**: Измерение времени выполнения каждого этапа
- **Метрики**: H2D transfer, kernel execution (дробная задержка), опционально D2H transfer
- **Функции**: StartTimer(), StopTimer(), ReportMetrics()

---

## 🔄 ПРОЦЕСС ОБРАБОТКИ

### Упрощённый Pipeline (до формирования матрицы с задержанными сигналами):

```
1. Загрузка данных (CPU)
   └─ SignalBuffer::LoadFromFile()
   
2. Инициализация GPU (OpenCL)
   └─ OpenCLBackend::Initialize()
   └─ Загрузка матрицы Лагранжа на GPU
   
3. H2D Transfer (Host → Device)
   └─ clEnqueueWriteBuffer() [профилируем]
   └─ Копирование сигналов на GPU
   
4. Дробная задержка (GPU Kernel)
   └─ kernel_fractional_delay.cl [профилируем]
   └─ Формирование матрицы с задержанными сигналами
   
5. Опционально: D2H Transfer (Device → Host)
   └─ clEnqueueReadBuffer() [профилируем]
   └─ Копирование результата на хост для анализа
   └─ ИЛИ: результат остаётся на GPU для дальнейшей обработки
   
6. Сохранение результатов (CPU, только если copy_to_host=true)
   └─ SignalBuffer::SaveToFile()
```

---

## 🎯 ЦЕЛЕВЫЕ МЕТРИКИ ПРОИЗВОДИТЕЛЬНОСТИ

### RTX3060 (Ubuntu, OpenCL):
- **Общее время (E2E)**: минимизировать (цель < 6 сек для 256 лучей × 1.3M точек)
- **H2D Transfer**: < 200 мс
- **Дробная задержка**: основной bottleneck, оптимизировать (~4-5 сек)
- **D2H Transfer** (опционально): < 200 мс

---

## 📁 СТРУКТУРА ПРОЕКТА

```
LCH-Farrow/
├── CMakeLists.txt              # Главный файл сборки
├── include/                    # Заголовочные файлы
│   ├── signal_buffer.h
│   ├── filter_bank.h
│   ├── processing_pipeline.h
│   ├── profiling_engine.h
│   └── gpu_backend/
│       ├── igpu_backend.h
│       └── opencl_backend.h
├── src/                        # Исходный код
│   ├── main.cpp
│   ├── signal_buffer.cpp
│   ├── filter_bank.cpp
│   ├── processing_pipeline.cpp
│   ├── profiling_engine.cpp
│   └── gpu_backend/
│       ├── opencl_backend.cpp
│       └── gpu_factory.cpp
├── kernels/                    # OpenCL kernels
│   ├── kernel_fractional_delay.cl
│   ├── kernel_hadamard.cl
│   └── clfft_wrapper.cl
├── data/                       # Тестовые данные
│   └── test_signal.bin
├── Doc/                        # Документация
│   └── Plan/                   # Планы работ
│       ├── 00_ОБЩИЙ_ПЛАН.md
│       ├── 01_ДЕТАЛЬНЫЙ_ПЛАН.md (индекс)
│       ├── Step01_Настройка_окружения.md
│       ├── Step02_SignalBuffer.md
│       ├── Step03_FilterBank.md
│       ├── Step04_OpenCL_Backend.md
│       ├── Step05_Kernel_Задержка.md
│       ├── Step06_FFT_Интеграция.md
│       ├── Step07_Pipeline.md
│       ├── Step08_Профилирование.md
│       └── Step09_Оптимизация.md
├── build/                      # Сборка (gitignore)
└── Results/                    # Результаты тестов
    ├── JSON/                   # JSON отчёты
    └── Profiler/               # Профилирование
```

---

## 🔧 ТЕХНОЛОГИЧЕСКИЙ СТЕК

- **Язык**: C++17
- **GPU API**: OpenCL 2.0+
- **FFT библиотека**: clFFT или FFTW (через OpenCL)
- **Платформа**: Ubuntu Linux
- **Компилятор**: GCC/Clang
- **Система сборки**: CMake 3.20+
- **Профилирование**: OpenCL Events (clGetEventProfilingInfo)

---

## 📊 КРИТЕРИИ УСПЕХА

✅ **Функциональность**:
- Корректная обработка 1-256 лучей
- Поддержка 100-1300000 точек на луч
- Правильная дробная задержка
- Корректная FFT/IFFT свёртка

✅ **Производительность**:
- Минимальное время вычисления на GPU
- Профилирование всех этапов
- Оптимизация bottleneck операций

✅ **Кроссплатформенность**:
- Работа на NVIDIA RTX3060
- Работа на AMD GPU (если доступно)
- Единый код для разных GPU

✅ **Качество кода**:
- ООП архитектура
- Чистый, читаемый код
- Документация
- Тесты

---

## 🚀 ЭТАПЫ РАЗРАБОТКИ

### Этап 1: Фундамент (Неделя 1)
- Настройка CMake для OpenCL
- Базовая структура классов
- SignalBuffer и FilterBank
- Тестирование загрузки данных

### Этап 2: OpenCL Backend (Неделя 2)
- OpenCLBackend реализация
- GPU инициализация и обнаружение
- Базовые kernel'ы
- H2D/D2H transfer

### Этап 3: Обработка сигнала (Неделя 3)
- Kernel дробной задержки
- FFT/IFFT интеграция
- Hadamard multiply
- Полный pipeline

### Этап 4: Оптимизация (Неделя 4)
- Профилирование и анализ
- Оптимизация bottleneck'ов
- Тестирование на разных GPU
- Документация

---

## 📝 СТРУКТУРА ДЕТАЛЬНЫХ ПЛАНОВ

Детальный план разбит на отдельные файлы по шагам:

1. **Step01_Настройка_окружения.md** - CMake, структура проекта
2. **Step02_SignalBuffer.md** - Класс SignalBuffer
3. **Step03_FilterBank.md** - Класс FilterBank
4. **Step04_OpenCL_Backend.md** - Базовый OpenCL backend
5. **Step05_Kernel_Задержка.md** - Kernel дробной задержки
6. **Step06_FFT_Интеграция.md** - FFT/IFFT интеграция
7. **Step07_Pipeline.md** - ProcessingPipeline
8. **Step08_Профилирование.md** - ProfilingEngine
9. **Step09_Оптимизация.md** - Оптимизация и тестирование

Каждый файл содержит:
- Детальное описание задачи
- Спецификацию классов/функций
- Пошаговые инструкции
- Критерии готовности
- Тесты для проверки

---

*Обновлено: 2025-01-28*  
*Версия: 1.0*

